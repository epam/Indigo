{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONv8Cyef2WH_",
        "outputId": "51b917f9-cfd7-42ad-8c20-1cef74c64d7b"
      },
      "outputs": [],
      "source": [
        "import dgl\n",
        "import torch\n",
        "import numpy as np\n",
        "from indigo import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_MiCgvkX3BSM"
      },
      "outputs": [],
      "source": [
        "indigo = Indigo()\n",
        "indigo.setOption(\"ignore-stereochemistry-errors\", True)\n",
        "indigo.setOption(\"ignore-bad-valence\", True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using backend: pytorch\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dgl.data import DGLDataset\n",
        "from dgl.data.utils import split_dataset\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from dgl.nn.pytorch import Set2Set, NNConv\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import r2_score\n",
        "import pandas as pd\n",
        "from indigo.ml.mpp.preprocess import mol_to_graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc-lcC3kCm1c"
      },
      "source": [
        "**GCN for property prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Graph(num_nodes=20, num_edges=42,\n",
            "      ndata_schemes={'atomic': Scheme(shape=(60,), dtype=torch.int64)}\n",
            "      edata_schemes={'ord': Scheme(shape=(1,), dtype=torch.float32)}), tensor(4.8710))\n"
          ]
        }
      ],
      "source": [
        "file_name = \"Adrenergic_dataset.csv\"\n",
        "target =  \"logP\" # \"AdrA1A_PCHEMBL_VALUE\"\n",
        "smiles = \"Structure\"\n",
        "\n",
        "df = pd.read_csv(file_name)\n",
        "df = df.loc[df[target].notnull()]\n",
        "data = dict(zip(df[smiles], df[target]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Dataset*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 470,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MolDataset(DGLDataset):\n",
        "    def __init__(self, data):\n",
        "        super().__init__(name='mols')\n",
        "        \n",
        "    def process(self):\n",
        "        self.graphs = []\n",
        "        self.labels = []\n",
        "        for smiles, label in data.items():\n",
        "            self.graphs.append(mol_to_graph(smiles))\n",
        "            self.labels.append(label)\n",
        "\n",
        "        self.gclasses = len(self.labels)\n",
        "        self.dim_nfeats = len(self.graphs[0].ndata['atomic'][0])\n",
        "        self.dim_efeats = len(self.graphs[0].edata['ord'][0])\n",
        "        self.labels = torch.FloatTensor(self.labels)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "        return self.graphs[i], self.labels[i]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Dataloaders*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 472,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(dataset):\n",
        "    train_set, val_set, test_set = split_dataset(dataset, frac_list=None, shuffle=False, random_state=None)\n",
        "    train_loader = GraphDataLoader(dataset=train_set, shuffle=True, drop_last=False)\n",
        "    val_loader = GraphDataLoader(dataset=val_set, shuffle=True, drop_last=False)\n",
        "    test_loader = GraphDataLoader(dataset=test_set, shuffle=True, drop_last=False)\n",
        "    return train_loader, val_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MPNNGNN(nn.Module):\n",
        "\n",
        "    def __init__(self, node_in_feats, edge_in_feats, node_out_feats=64,\n",
        "                 edge_hidden_feats=128, num_step_message_passing=6):\n",
        "        super(MPNNGNN, self).__init__()\n",
        "\n",
        "        self.project_node_feats = nn.Sequential(\n",
        "            nn.Linear(node_in_feats, node_out_feats),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.num_step_message_passing = num_step_message_passing\n",
        "        edge_network = nn.Sequential(\n",
        "            nn.Linear(edge_in_feats, edge_hidden_feats),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(edge_hidden_feats, node_out_feats * node_out_feats)\n",
        "        )\n",
        "        self.gnn_layer = NNConv(\n",
        "            in_feats=node_out_feats,\n",
        "            out_feats=node_out_feats,\n",
        "            edge_func=edge_network,\n",
        "            aggregator_type='sum'\n",
        "        )\n",
        "        self.gru = nn.GRU(node_out_feats, node_out_feats)\n",
        "\n",
        "    def forward(self, g, node_feats, edge_feats):\n",
        "        node_feats = self.project_node_feats(node_feats) \n",
        "        hidden_feats = node_feats.unsqueeze(0)           \n",
        "\n",
        "        for _ in range(self.num_step_message_passing):\n",
        "            node_feats = F.relu(self.gnn_layer(g, node_feats, edge_feats))\n",
        "            node_feats, hidden_feats = self.gru(node_feats.unsqueeze(0), hidden_feats)\n",
        "            node_feats = node_feats.squeeze(0)\n",
        "\n",
        "        return node_feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLPRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, in_feats, hidden_feats, n_tasks, dropout=0.):\n",
        "        super(MLPRegressor, self).__init__()\n",
        "\n",
        "        self.predict = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(in_feats, hidden_feats),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_feats, n_tasks)\n",
        "        )\n",
        "\n",
        "    def forward(self, h):\n",
        "        return self.predict(h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MPNNRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, in_node_feats, in_edge_feats, node_hidden_dim, edge_hidden_dim,\n",
        "                 num_step_message_passing, num_step_set2set, num_layer_set2set, n_tasks,\n",
        "                 regressor_hidden_feats=128, dropout=0.):\n",
        "        super(MPNNRegressor, self).__init__()\n",
        "        self.gnn = MPNNGNN(in_node_feats, in_edge_feats, node_hidden_dim,\n",
        "                           edge_hidden_dim, num_step_message_passing)\n",
        "        self.readout = Set2Set(node_hidden_dim, num_step_set2set, num_layer_set2set)\n",
        "        readout_feats = 2 * node_hidden_dim\n",
        "        self.regressor = MLPRegressor(readout_feats, regressor_hidden_feats, n_tasks, dropout)\n",
        "\n",
        "\n",
        "    def forward(self, bg, node_feats, edge_feats):\n",
        "\n",
        "        feats = self.gnn(bg, node_feats, edge_feats)\n",
        "        h_g = self.readout(bg, feats)\n",
        "\n",
        "        return self.regressor(h_g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Parametrs*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\n",
        "  \"lr\": 3e-4,\n",
        "  \"weight_decay\": 0,\n",
        "  \"patience\": 30,\n",
        "  \"batch_size\": 128,\n",
        "  \"node_out_feats\": 64,\n",
        "  \"edge_hidden_feats\": 128,\n",
        "  \"num_step_message_passing\": 6,\n",
        "  \"num_step_set2set\": 6,\n",
        "  \"num_layer_set2set\": 3\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 500,
      "metadata": {},
      "outputs": [],
      "source": [
        "MPNN_params = {\n",
        "    'node_hidden_dim': 64,\n",
        "    'edge_hidden_dim': 16,\n",
        "    'num_step_message_passing': 2,\n",
        "    'num_step_set2set': 3,\n",
        "    'num_layer_set2set': 2,\n",
        "    'regressor_hidden_feats': 32,\n",
        "    'dropout': 0.,\n",
        "    'n_tasks': 1\n",
        "}\n",
        "\n",
        "dataset = MolDataset(data)\n",
        "train_loader, val_loader, test_loader = load_data(dataset)\n",
        "num_epoch = 20\n",
        "model = MPNNRegressor(dataset.dim_nfeats, dataset.dim_efeats, **MPNN_params)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fcn = torch.nn.SmoothL1Loss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Training*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 501,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]C:\\Users\\Diana_Peres\\Miniconda3\\envs\\indigo\\lib\\site-packages\\torch\\nn\\modules\\loss.py:912: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
            "C:\\Users\\Diana_Peres\\Miniconda3\\envs\\indigo\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "  5%|▌         | 1/20 [00:42<13:19, 42.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0/20............. Loss: 0.7122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 2/20 [01:26<13:00, 43.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/20............. Loss: 0.0912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 3/20 [02:11<12:28, 44.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2/20............. Loss: 0.0223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 4/20 [02:55<11:46, 44.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3/20............. Loss: 0.7424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 5/20 [03:40<11:04, 44.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4/20............. Loss: 1.0003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 6/20 [04:27<10:36, 45.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5/20............. Loss: 0.1003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 7/20 [05:14<09:56, 45.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 6/20............. Loss: 0.0304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 8/20 [06:03<09:20, 46.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 7/20............. Loss: 0.3217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 9/20 [06:50<08:35, 46.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 8/20............. Loss: 0.0724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 10/20 [07:46<08:16, 49.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 9/20............. Loss: 0.0768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 11/20 [08:43<07:47, 51.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10/20............. Loss: 0.1326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 12/20 [09:33<06:50, 51.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 11/20............. Loss: 0.3476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 13/20 [10:20<05:50, 50.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 12/20............. Loss: 0.3130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 14/20 [11:08<04:56, 49.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 13/20............. Loss: 1.0708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 15/20 [11:58<04:08, 49.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 14/20............. Loss: 0.0530\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 16/20 [12:43<03:13, 48.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 15/20............. Loss: 0.0242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 17/20 [13:29<02:22, 47.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 16/20............. Loss: 0.1225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 18/20 [14:15<01:34, 47.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 17/20............. Loss: 0.0576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 19/20 [15:02<00:47, 47.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 18/20............. Loss: 0.0333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [15:46<00:00, 47.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 19/20............. Loss: 0.1361\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in tqdm(range(num_epoch)):\n",
        "    losses = list()\n",
        "    for batched_graph, labels in train_loader:\n",
        "\n",
        "        node_feats = batched_graph.ndata['atomic'].float()\n",
        "        edge_feats = batched_graph.edata['ord'].float()\n",
        "        prediction = model(batched_graph, node_feats, edge_feats)\n",
        "        loss = loss_fcn(prediction, labels)\n",
        "        losses.append(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print('Epoch: {}/{}.............'.format(epoch, num_epoch), end=' ')\n",
        "    print(\"Loss: {:.4f}\".format(loss.mean()))\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 502,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def evaluate(model, loader):\n",
        "   \n",
        "    preds = []\n",
        "    labels = []\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batched_graph, label in loader:\n",
        "           \n",
        "            node_feats = batched_graph.ndata['atomic'].float()\n",
        "            edge_feats = batched_graph.edata['ord'].float()\n",
        "            prediction = model(batched_graph, node_feats, edge_feats)\n",
        "            preds.append(float(prediction))\n",
        "            labels.append(float(label))\n",
        "\n",
        "        print(f'R2 score: {r2_score(labels, preds):.2f}')\n",
        "        print(f'MAE: {mean_absolute_error(labels, preds):.2f}')\n",
        "\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 503,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 score: 0.66\n",
            "MAE: 0.41\n"
          ]
        }
      ],
      "source": [
        "evaluate(model, val_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of mol-to-g.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
